{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6ae033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write(path,data):\n",
    "    with open(path,'w',encoding='utf-8') as file:\n",
    "        json.dump(data,file,indent=4,ensure_ascii=False)\n",
    "def read(path):\n",
    "    with open(path,'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "import re\n",
    "def extract_video_numbers_first_only(text):\n",
    "    \"\"\"\n",
    "    只返回第一个匹配的数字\n",
    "    \n",
    "    Args:\n",
    "        text (str): 输入的字符串\n",
    "    \n",
    "    Returns:\n",
    "        int or None: 第一个找到的数字，如果没有找到则返回None\n",
    "    \"\"\"\n",
    "    pattern = r'(?i)\\bvideo\\s+(10|[0-9])\\b'\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4c013",
   "metadata": {},
   "source": [
    "### GET Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee62de",
   "metadata": {},
   "outputs": [],
   "source": "all_data = read(\"./data/IVCR-200K.json\")\nnew_data = []\nfor sample in all_data:\n    if sample.get('split') == 'train' and sample['type'] != [0]:\n        new_data.append(sample)\ntrain_data = []\nfor sample in new_data:\n    if sample.get('split') == 'train' and sample['type'] != [0]:\n        sub_sample = []\n        for conv in sample.get('conversations'):\n            if conv.get('from') == 'human':\n                sub_conv = dict()\n                sub_conv['user'] = conv.get('value').strip()\n                sub_conv['text_id'] = conv.get('text_id')\n            else:\n                sub_conv['assistance'] = conv.get('value').strip()\n                sub_conv['video_id'] = conv.get('video_id')\n                if conv.get('candidate_videos'):\n                    sub_conv['candidate_videos'] = conv.get('candidate_videos')\n                sub_conv['gt_se'] = conv.get('gt_se')\n                sub_sample.append(sub_conv)\n                if len(sub_sample) <= 10:\n                    train_data.append(sub_sample.copy())\nwrite(\"./data/IVCR_no_type0_train.json\",train_data)\n#Build data that conforms to large language model conversation format\ntrain_dialogues_data = []\nsystem_message = \"You are an excellent video retrieval AI assistant.\"\nCurrent_Video = \"Current video : <VID> {VID1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>.\"\nfor sample in train_data:\n    messages = []\n    messages.append({\"role\":\"system\",\"content\":system_message})\n    for sub_data  in sample:\n        user_question = sub_data.get('user').strip()\n        if sub_data.get('gt_se') == [-1,-1]:\n            videos = sub_data.get('candidate_videos')\n            candiate_video = \"Candidate videos : \"\n            for i in range(10):\n                a = f\"<VID> {i+1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>\"\n                if i<9:\n                    a += ','\n                    candiate_video += a\n                else:\n                    a += '.'\n                    candiate_video += a\n\n            user_question = candiate_video + user_question\n            \n            assistance_answer = sub_data.get('assistance').strip()\n            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n        else:\n            assistance_answer = sub_data.get('assistance').strip()\n            video_index = extract_video_numbers_first_only(assistance_answer)\n            video_caption = Current_Video.format(VID1 = video_index)\n            user_question = video_caption + user_question\n            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n    train_dialogues_data.append(messages)\nwrite(\"./data/IVCR_no_type0_dialogues_train.json\",train_dialogues_data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e590498",
   "metadata": {},
   "outputs": [],
   "source": "#Get video path list\ndata = read('./data/IVCR_no_type0_train.json')\nall_video_list = []\nfor sample in data:\n    video_list = []\n    for sub_data  in sample:\n        if sub_data.get('gt_se') == [-1,-1]:\n            video_list.append(sub_data['candidate_videos'])\n        else:\n            video_list.append(sub_data['video_id'])\n    all_video_list.append(video_list)\nwrite('./data/IVCR_no_type0_dialogues_video_list_train.json',all_video_list)"
  },
  {
   "cell_type": "markdown",
   "id": "3dd50c77",
   "metadata": {},
   "source": [
    "### Get Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1c911",
   "metadata": {},
   "outputs": [],
   "source": "#Remove samples from the test set in the original data where first-round dialogue R@10 or R@1 retrieval failed\nall_data = read(\"./data/IVCR-200K.json\")\nnew_data = []\ncount = 0\ntongji = dict()\nsum = 0\nfor sample in all_data:\n    if sample.get('split') == 'test' and sample['type'] != [0]:\n        count+=1\n        sub_sample = []\n        convs = sample['conversations']\n        if sample['type'] != [7]:\n            for i,conv in enumerate(convs):\n                if i == 0 and conv['from'] == 'human' and convs[i+1]['gt_se'] == [-1,-1]:\n                    top10_video  = convs[i+1]['candidate_videos']\n                    gt_video = convs[i+1]['video_id']\n                    if gt_video in top10_video:\n                        new_data.append(sample)\n                        break\n                elif i == 0 and conv['from'] == 'human' and convs[i+1]['gt_se'] != [-1,-1]:\n                    top10_video  = convs[i+1]['candidate_videos']\n                    gt_video = convs[i+1]['video_id']  \n                    if gt_video == top10_video[0]:\n                        new_data.append(sample)\n                        break\n        else:\n            new_convs = []\n            for i,conv in enumerate(convs):\n                if conv['from'] == 'human' and convs[i+1]['gt_se'] == [-1,-1]:\n                    top10_video  = convs[i+1]['candidate_videos']\n                    gt_video = convs[i+1]['video_id']\n                    if gt_video in top10_video:\n                        new_convs.append(conv)\n                elif conv['from'] == 'human' and convs[i+1]['gt_se'] != [-1,-1]:\n                    top10_video  = convs[i+1]['candidate_videos']\n                    gt_video = convs[i+1]['video_id']\n                    if gt_video == top10_video[0]:\n                        new_convs.append(conv)\n            sample['conversations'] = new_convs\n            new_data.append(sample)\nprint(count)\nprint(sum)\nwrite('./data/IVCR-200K-no-zero-test.json',new_data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9edc75",
   "metadata": {},
   "outputs": [],
   "source": "#Build data that conforms to large language model conversation format\nall_data = read('./data/IVCR-200K-no-zero-test.json')\nnew_data = []\ndata_cate = dict()\nfor sample in all_data:\n    if sample.get('split') == 'test' and sample['type'] != [0]:\n        if sample.get('type')[0] not in data_cate:\n            data_cate[sample.get('type')[0]] = 1\n        else:\n            data_cate[sample.get('type')[0]] += 1\n        sub_sample = []\n        for conv in sample.get('conversations'):\n            if conv.get('from') == 'human':\n                sub_conv = dict()\n                sub_conv['user'] = conv.get('value').strip()\n                sub_conv['text_id'] = conv.get('text_id')\n            else:\n                sub_conv['assistance'] = conv.get('value').strip()\n                sub_conv['video_id'] = conv.get('video_id')\n                if conv.get('candidate_videos'):\n                    sub_conv['candidate_videos'] = conv.get('candidate_videos')\n                sub_conv['gt_se'] = conv.get('gt_se')\n                sub_sample.append(sub_conv)\n                if len(sub_sample) <= 10:\n                    new_data.append(sub_sample.copy())\nwrite('./data/IVCR_no_type0_no_zero_test.json',new_data)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382d81c",
   "metadata": {},
   "outputs": [],
   "source": "data = read('./data/IVCR_no_type0_no_zero_test.json')\ndialogues = []\nsystem_message = \"You are an excellent video retrieval AI assistant.\"\nCurrent_Video = \"Current video : <VID> {VID1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>.\"\nfor sample in data:\n    messages = []\n    messages.append({\"role\":\"system\",\"content\":system_message})\n    for sub_data  in sample:\n        user_question = sub_data.get('user').strip()\n        if sub_data.get('gt_se') == [-1,-1]:\n            videos = sub_data.get('candidate_videos')\n            candiate_video = \"Candidate videos : \"\n            for i in range(10):\n                a = f\"<VID> {i+1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>\"\n                if i<9:\n                    a += ','\n                    candiate_video += a\n                else:\n                    a += '.'\n                    candiate_video += a\n\n            user_question = candiate_video + user_question\n            \n            assistance_answer = sub_data.get('assistance').strip()\n            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n        else:\n            assistance_answer = sub_data.get('assistance').strip()\n            video_index = extract_video_numbers_first_only(assistance_answer)\n            video_caption = Current_Video.format(VID1 = video_index)\n            user_question = video_caption + user_question\n            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n    dialogues.append(messages)\nwrite(\"./data/IVCR_no_type0_no_zero_dialogues_test.json\",dialogues)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f1b98",
   "metadata": {},
   "outputs": [],
   "source": "#Get video path list\ndata = read('./data/IVCR_no_type0_no_zero_test.json')\nall_video_list = []\nfor sample in data:\n    video_list = []\n    for sub_data  in sample:\n        if sub_data.get('gt_se') == [-1,-1]:\n            video_list.append(sub_data['candidate_videos'])\n        else:\n            video_list.append(sub_data['video_id'])\n    all_video_list.append(video_list)\nwrite('./data/IVCR_no_type0_no_zero_dialogues_video_list_test.json',all_video_list)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e95ba",
   "metadata": {},
   "outputs": [],
   "source": "data = read(\"./data/IVCR_no_type0_no_zero_dialogues_test.json\")\nnew_data = []\ncount = 0\nfor s in data:\n    if len(s) <= 15:\n        count += 1\n        new_data.append(s)\nprint(f\"len(new_data) : {count}\")\nwrite('./data/IVCR_no_type0_no_zero_dialogues_test_7.json',new_data)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}