{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6ae033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def write(path,data):\n",
    "    with open(path,'w',encoding='utf-8') as file:\n",
    "        json.dump(data,file,indent=4,ensure_ascii=False)\n",
    "def read(path):\n",
    "    with open(path,'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "import re\n",
    "def extract_video_numbers_first_only(text):\n",
    "    \"\"\"\n",
    "    只返回第一个匹配的数字\n",
    "    \n",
    "    Args:\n",
    "        text (str): 输入的字符串\n",
    "    \n",
    "    Returns:\n",
    "        int or None: 第一个找到的数字，如果没有找到则返回None\n",
    "    \"\"\"\n",
    "    pattern = r'(?i)\\bvideo\\s+(10|[0-9])\\b'\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae4c013",
   "metadata": {},
   "source": [
    "### GET Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ee62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = read(\"./data/IVCR-200K.json\")\n",
    "new_data = []\n",
    "for sample in all_data:\n",
    "    if sample.get('split') == 'train' and sample['type'] != [0]:\n",
    "        new_data.append(sample)\n",
    "train_data = []\n",
    "for sample in new_data:\n",
    "    if sample.get('split') == 'train' and sample['type'] != [0]:\n",
    "        sub_sample = []\n",
    "        for conv in sample.get('conversations'):\n",
    "            if conv.get('from') == 'human':\n",
    "                sub_conv = dict()\n",
    "                sub_conv['user'] = conv.get('value').strip()\n",
    "                sub_conv['text_id'] = conv.get('text_id')\n",
    "            else:\n",
    "                sub_conv['assistance'] = conv.get('value').strip()\n",
    "                sub_conv['video_id'] = conv.get('video_id')\n",
    "                if conv.get('candidate_videos'):\n",
    "                    sub_conv['candidate_videos'] = conv.get('candidate_videos')\n",
    "                sub_conv['gt_se'] = conv.get('gt_se')\n",
    "                sub_sample.append(sub_conv)\n",
    "                if len(sub_sample) <= 10:\n",
    "                    train_data.append(sub_sample.copy())\n",
    "write(\"./data/IVCR_no_type0_train.json\",train_data)\n",
    "#Build data that conforms to large language model conversation format\n",
    "train_dialogues_data = []\n",
    "system_message = \"You are an excellent video retrieval AI assistant.\"\n",
    "Current_Video = \"Current video : <VID> {VID1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>.\"\n",
    "for sample in train_data:\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"system\",\"content\":system_message})\n",
    "    for sub_data  in sample:\n",
    "        user_question = sub_data.get('user').strip()\n",
    "        if sub_data.get('gt_se') == [-1,-1]:\n",
    "            videos = sub_data.get('candidate_videos')\n",
    "            candiate_video = \"Candidate videos : \"\n",
    "            for i in range(10):\n",
    "                a = f\"<VID> {i+1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>\"\n",
    "                if i<9:\n",
    "                    a += ','\n",
    "                    candiate_video += a\n",
    "                else:\n",
    "                    a += '.'\n",
    "                    candiate_video += a\n",
    "\n",
    "            user_question = candiate_video + user_question\n",
    "            \n",
    "            assistance_answer = sub_data.get('assistance').strip()\n",
    "            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n",
    "            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n",
    "        else:\n",
    "            assistance_answer = sub_data.get('assistance').strip()\n",
    "            video_index = extract_video_numbers_first_only(assistance_answer)\n",
    "            video_caption = Current_Video.format(VID1 = video_index)\n",
    "            user_question = video_caption + user_question\n",
    "            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n",
    "            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n",
    "    train_dialogues_data.append(messages)\n",
    "write(\"./data/IVCR_no_type0_dialogues_train.json\",train_dialogues_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e590498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get video path list\n",
    "data = read('./data/IVCR_no_type0_train.json')\n",
    "all_video_list = []\n",
    "for sample in data:\n",
    "    video_list = []\n",
    "    for sub_data  in sample:\n",
    "        if sub_data.get('gt_se') == [-1,-1]:\n",
    "            video_list.append(sub_data['candidate_videos'])\n",
    "        else:\n",
    "            video_list.append(sub_data['video_id'])\n",
    "    all_video_list.append(video_list)\n",
    "write('./data/IVCR_no_type0_dialogues_video_list_train.json',all_video_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd50c77",
   "metadata": {},
   "source": [
    "### Get Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd1c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5058\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Remove samples from the test set in the original data where first-round dialogue R@10 or R@1 retrieval failed\n",
    "all_data = read(\"./data/IVCR-200K.json\")\n",
    "new_data = []\n",
    "count = 0\n",
    "tongji = dict()\n",
    "sum = 0\n",
    "for sample in all_data:\n",
    "    if sample.get('split') == 'test' and sample['type'] != [0]:\n",
    "        count+=1\n",
    "        sub_sample = []\n",
    "        convs = sample['conversations']\n",
    "        if sample['type'] != [7]:\n",
    "            for i,conv in enumerate(convs):\n",
    "                if i == 0 and conv['from'] == 'human' and convs[i+1]['gt_se'] == [-1,-1]:\n",
    "                    top10_video  = convs[i+1]['candidate_videos']\n",
    "                    gt_video = convs[i+1]['video_id']\n",
    "                    if gt_video in top10_video:\n",
    "                        new_data.append(sample)\n",
    "                        break\n",
    "                elif i == 0 and conv['from'] == 'human' and convs[i+1]['gt_se'] != [-1,-1]:\n",
    "                    top10_video  = convs[i+1]['candidate_videos']\n",
    "                    gt_video = convs[i+1]['video_id']  \n",
    "                    if gt_video == top10_video[0]:\n",
    "                        new_data.append(sample)\n",
    "                        break\n",
    "        else:\n",
    "            new_convs = []\n",
    "            for i,conv in enumerate(convs):\n",
    "                if conv['from'] == 'human' and convs[i+1]['gt_se'] == [-1,-1]:\n",
    "                    top10_video  = convs[i+1]['candidate_videos']\n",
    "                    gt_video = convs[i+1]['video_id']\n",
    "                    if gt_video in top10_video:\n",
    "                        new_convs.append(conv)\n",
    "                elif conv['from'] == 'human' and convs[i+1]['gt_se'] != [-1,-1]:\n",
    "                    top10_video  = convs[i+1]['candidate_videos']\n",
    "                    gt_video = convs[i+1]['video_id']\n",
    "                    if gt_video == top10_video[0]:\n",
    "                        new_convs.append(conv)\n",
    "            sample['conversations'] = new_convs\n",
    "            new_data.append(sample)\n",
    "print(count)\n",
    "print(sum)\n",
    "write('./data/IVCR-200K-no-zero-test.json',new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9edc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build data that conforms to large language model conversation format\n",
    "all_data = read('./data/IVCR-200K-no-zero-test.json')\n",
    "new_data = []\n",
    "data_cate = dict()\n",
    "for sample in all_data:\n",
    "    if sample.get('split') == 'test' and sample['type'] != [0]:\n",
    "        if sample.get('type')[0] not in data_cate:\n",
    "            data_cate[sample.get('type')[0]] = 1\n",
    "        else:\n",
    "            data_cate[sample.get('type')[0]] += 1\n",
    "        sub_sample = []\n",
    "        for conv in sample.get('conversations'):\n",
    "            if conv.get('from') == 'human':\n",
    "                sub_conv = dict()\n",
    "                sub_conv['user'] = conv.get('value').strip()\n",
    "                sub_conv['text_id'] = conv.get('text_id')\n",
    "            else:\n",
    "                sub_conv['assistance'] = conv.get('value').strip()\n",
    "                sub_conv['video_id'] = conv.get('video_id')\n",
    "                if conv.get('candidate_videos'):\n",
    "                    sub_conv['candidate_videos'] = conv.get('candidate_videos')\n",
    "                sub_conv['gt_se'] = conv.get('gt_se')\n",
    "                sub_sample.append(sub_conv)\n",
    "                if len(sub_sample) <= 10:\n",
    "                    new_data.append(sub_sample.copy())\n",
    "write('./data/IVCR_no_type0_no_zero_test.json',new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c382d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read('./data/IVCR_no_type0_no_zero_test.json')\n",
    "dialogues = []\n",
    "system_message = \"You are an excellent video retrieval AI assistant.\"\n",
    "Current_Video = \"Current video : <VID> {VID1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>.\"\n",
    "for sample in data:\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"system\",\"content\":system_message})\n",
    "    for sub_data  in sample:\n",
    "        user_question = sub_data.get('user').strip()\n",
    "        if sub_data.get('gt_se') == [-1,-1]:\n",
    "            videos = sub_data.get('candidate_videos')\n",
    "            candiate_video = \"Candidate videos : \"\n",
    "            for i in range(10):\n",
    "                a = f\"<VID> {i+1} </VID> <VIDEO> <VIDEOTOKEN> </VIDEO>\"\n",
    "                if i<9:\n",
    "                    a += ','\n",
    "                    candiate_video += a\n",
    "                else:\n",
    "                    a += '.'\n",
    "                    candiate_video += a\n",
    "\n",
    "            user_question = candiate_video + user_question\n",
    "            \n",
    "            assistance_answer = sub_data.get('assistance').strip()\n",
    "            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n",
    "            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n",
    "        else:\n",
    "            assistance_answer = sub_data.get('assistance').strip()\n",
    "            video_index = extract_video_numbers_first_only(assistance_answer)\n",
    "            video_caption = Current_Video.format(VID1 = video_index)\n",
    "            user_question = video_caption + user_question\n",
    "            messages.append({\"role\":\"user\",\"content\":user_question.strip()})\n",
    "            messages.append({\"role\":\"assistant\",\"content\":assistance_answer})\n",
    "    dialogues.append(messages)\n",
    "write(\"./data/IVCR_no_type0_no_zero_dialogues_test.json\",dialogues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb1f1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get video path list\n",
    "data = read('./data/IVCR_no_type0_no_zero_test.json')\n",
    "all_video_list = []\n",
    "for sample in data:\n",
    "    video_list = []\n",
    "    for sub_data  in sample:\n",
    "        if sub_data.get('gt_se') == [-1,-1]:\n",
    "            video_list.append(sub_data['candidate_videos'])\n",
    "        else:\n",
    "            video_list.append(sub_data['video_id'])\n",
    "    all_video_list.append(video_list)\n",
    "write('./data/IVCR_no_type0_no_zero_dialogues_video_list_test.json',all_video_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7e95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(new_data) : 8545\n"
     ]
    }
   ],
   "source": [
    "data = read(\"./data/IVCR_no_type0_no_zero_dialogues_test.json\")\n",
    "new_data = []\n",
    "count = 0\n",
    "for s in data:\n",
    "    if len(s) <= 15:\n",
    "        count += 1\n",
    "        new_data.append(s)\n",
    "print(f\"len(new_data) : {count}\")\n",
    "write('./data/IVCR_no_type0_no_zero_dialogues_test_7.json',new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ivcr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
